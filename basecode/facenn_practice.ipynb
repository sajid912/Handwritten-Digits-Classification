{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:52.4218009479%\n",
      "\n",
      " Validation set Accuracy:50.5816135084%\n",
      "\n",
      " Test set Accuracy:50.1892505678%\n",
      "\n",
      " Time taken:56.4353129864\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:52.2748815166%\n",
      "\n",
      " Validation set Accuracy:50.7692307692%\n",
      "\n",
      " Test set Accuracy:50.4163512491%\n",
      "\n",
      " Time taken:67.9725749493\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:51.9194312796%\n",
      "\n",
      " Validation set Accuracy:50.7317073171%\n",
      "\n",
      " Test set Accuracy:50.7191521575%\n",
      "\n",
      " Time taken:53.8966569901\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:51.4644549763%\n",
      "\n",
      " Validation set Accuracy:51.4821763602%\n",
      "\n",
      " Test set Accuracy:50.6056018168%\n",
      "\n",
      " Time taken:49.0646181107\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:51.6777251185%\n",
      "\n",
      " Validation set Accuracy:50.8067542214%\n",
      "\n",
      " Test set Accuracy:50.6813020439%\n",
      "\n",
      " Time taken:62.6161670685\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:51.0047393365%\n",
      "\n",
      " Validation set Accuracy:51.5947467167%\n",
      "\n",
      " Test set Accuracy:50.6434519304%\n",
      "\n",
      " Time taken:328.872258902\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:50.8293838863%\n",
      "\n",
      " Validation set Accuracy:51.3696060038%\n",
      "\n",
      " Test set Accuracy:50.5299015897%\n",
      "\n",
      " Time taken:138.004972935\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:52.1800947867%\n",
      "\n",
      " Validation set Accuracy:51.4821763602%\n",
      "\n",
      " Test set Accuracy:50.5677517033%\n",
      "\n",
      " Time taken:52.0254130363\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:52.4360189573%\n",
      "\n",
      " Validation set Accuracy:50.6191369606%\n",
      "\n",
      " Test set Accuracy:50.6434519304%\n",
      "\n",
      " Time taken:54.8275339603\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:51.5781990521%\n",
      "\n",
      " Validation set Accuracy:51.2945590994%\n",
      "\n",
      " Test set Accuracy:50.6813020439%\n",
      "\n",
      " Time taken:50.1092550755\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:51.5118483412%\n",
      "\n",
      " Validation set Accuracy:51.4821763602%\n",
      "\n",
      " Test set Accuracy:50.6813020439%\n",
      "\n",
      " Time taken:52.7780778408\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:51.1279620853%\n",
      "\n",
      " Validation set Accuracy:51.5947467167%\n",
      "\n",
      " Test set Accuracy:50.757002271%\n",
      "\n",
      " Time taken:72.9998400211\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:50.981042654%\n",
      "\n",
      " Validation set Accuracy:51.6322701689%\n",
      "\n",
      " Test set Accuracy:50.7191521575%\n",
      "\n",
      " Time taken:94.7031831741\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:50.8341232227%\n",
      "\n",
      " Validation set Accuracy:51.4071294559%\n",
      "\n",
      " Test set Accuracy:50.7191521575%\n",
      "\n",
      " Time taken:109.843902111\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:52.1090047393%\n",
      "\n",
      " Validation set Accuracy:51.4446529081%\n",
      "\n",
      " Test set Accuracy:50.1892505678%\n",
      "\n",
      " Time taken:51.51668787\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:51.9383886256%\n",
      "\n",
      " Validation set Accuracy:51.4446529081%\n",
      "\n",
      " Test set Accuracy:50.6813020439%\n",
      "\n",
      " Time taken:50.2499878407\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:51.4928909953%\n",
      "\n",
      " Validation set Accuracy:51.5572232645%\n",
      "\n",
      " Test set Accuracy:50.5677517033%\n",
      "\n",
      " Time taken:46.6032559872\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:51.2085308057%\n",
      "\n",
      " Validation set Accuracy:51.5947467167%\n",
      "\n",
      " Test set Accuracy:50.757002271%\n",
      "\n",
      " Time taken:49.3028988838\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:51.1374407583%\n",
      "\n",
      " Validation set Accuracy:51.5572232645%\n",
      "\n",
      " Test set Accuracy:50.7948523846%\n",
      "\n",
      " Time taken:47.088531971\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:50.971563981%\n",
      "\n",
      " Validation set Accuracy:51.5196998124%\n",
      "\n",
      " Test set Accuracy:50.6056018168%\n",
      "\n",
      " Time taken:48.5981137753\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:50.7535545024%\n",
      "\n",
      " Validation set Accuracy:51.3696060038%\n",
      "\n",
      " Test set Accuracy:50.7191521575%\n",
      "\n",
      " Time taken:162.440315962\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:50.1611374408%\n",
      "\n",
      " Validation set Accuracy:50.0938086304%\n",
      "\n",
      " Test set Accuracy:50.0378501136%\n",
      "\n",
      " Time taken:6.88441514969\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:50.0853080569%\n",
      "\n",
      " Validation set Accuracy:50.6941838649%\n",
      "\n",
      " Test set Accuracy:51.0219530659%\n",
      "\n",
      " Time taken:6.89212298393\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:49.9526066351%\n",
      "\n",
      " Validation set Accuracy:49.9812382739%\n",
      "\n",
      " Test set Accuracy:50.0%\n",
      "\n",
      " Time taken:7.00628805161\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:50.028436019%\n",
      "\n",
      " Validation set Accuracy:49.9812382739%\n",
      "\n",
      " Test set Accuracy:49.9621498864%\n",
      "\n",
      " Time taken:7.13752007484\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:51.0710900474%\n",
      "\n",
      " Validation set Accuracy:51.5196998124%\n",
      "\n",
      " Test set Accuracy:50.6434519304%\n",
      "\n",
      " Time taken:224.626829147\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:50.0236966825%\n",
      "\n",
      " Validation set Accuracy:50.1688555347%\n",
      "\n",
      " Test set Accuracy:50.3028009084%\n",
      "\n",
      " Time taken:7.16747808456\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:49.9241706161%\n",
      "\n",
      " Validation set Accuracy:49.9061913696%\n",
      "\n",
      " Test set Accuracy:50.1514004542%\n",
      "\n",
      " Time taken:6.92173504829\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:50.0521327014%\n",
      "\n",
      " Validation set Accuracy:50.0187617261%\n",
      "\n",
      " Test set Accuracy:50.0378501136%\n",
      "\n",
      " Time taken:7.98490405083\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:51.8246445498%\n",
      "\n",
      " Validation set Accuracy:51.4821763602%\n",
      "\n",
      " Test set Accuracy:50.7191521575%\n",
      "\n",
      " Time taken:59.9887478352\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:49.9478672986%\n",
      "\n",
      " Validation set Accuracy:49.9812382739%\n",
      "\n",
      " Test set Accuracy:50.0%\n",
      "\n",
      " Time taken:7.50479698181\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:51.4075829384%\n",
      "\n",
      " Validation set Accuracy:51.6322701689%\n",
      "\n",
      " Test set Accuracy:50.6434519304%\n",
      "\n",
      " Time taken:82.5305120945\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:51.0710900474%\n",
      "\n",
      " Validation set Accuracy:51.5196998124%\n",
      "\n",
      " Test set Accuracy:50.757002271%\n",
      "\n",
      " Time taken:47.3967790604\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:50.9383886256%\n",
      "\n",
      " Validation set Accuracy:50.5065666041%\n",
      "\n",
      " Test set Accuracy:50.3785011355%\n",
      "\n",
      " Time taken:20.6742920876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6645e5c086fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m}\u001b[0m    \u001b[0;31m# Preferred value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mnn_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnObjFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m#Reshape nnParams from 1D vector into w1 and w2 matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_minimize_cg\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk, old_fval,\n\u001b[0;32m-> 1247\u001b[0;31m                                           old_old_fval, c2=0.4, amin=1e-100, amax=1e100)\n\u001b[0m\u001b[1;32m   1248\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;31m# Line search failed to find a better solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m    764\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/linesearch.pyc\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/linesearch.pyc\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'FG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/linesearch.pyc\u001b[0m in \u001b[0;36mphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6645e5c086fe>\u001b[0m in \u001b[0;36mnnObjFunction\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0minput_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create input bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mbiased_training_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add input bias to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0maj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiased_training_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1_transpose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Product of W and input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sajidkhan/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5151\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Comparing single layer MLP with deep MLP (using TensorFlow)\n",
    "'''\n",
    "import pickle, time\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.io import loadmat\n",
    "from math import sqrt\n",
    "from numpy import exp\n",
    "\n",
    "# Do not change this\n",
    "def initializeWeights(n_in,n_out):\n",
    "    \"\"\"\n",
    "    # initializeWeights return the random weights for Neural Network given the\n",
    "    # number of node in the input layer and output layer\n",
    "\n",
    "    # Input:\n",
    "    # n_in: number of nodes of the input layer\n",
    "    # n_out: number of nodes of the output layer\n",
    "                            \n",
    "    # Output: \n",
    "    # W: matrix of random initial weights with size (n_out x (n_in + 1))\"\"\"\n",
    "    epsilon = sqrt(6) / sqrt(n_in + n_out + 1);\n",
    "    W = (np.random.rand(n_out, n_in + 1)*2* epsilon) - epsilon;\n",
    "    return W\n",
    "\n",
    "\n",
    "\n",
    "# Replace this with your sigmoid implementation\n",
    "def sigmoid(z):\n",
    "    \"\"\"# Notice that z can be a scalar, a vector or a matrix\n",
    "    # return the sigmoid of input z\"\"\"\n",
    "\n",
    "    e = 1 / (1 + exp(-z))\n",
    "    return e \n",
    "\n",
    "# Replace this with your nnObjFunction implementation\n",
    "def nnObjFunction(params, *args):\n",
    "    \"\"\"% nnObjFunction computes the value of objective function (negative log \n",
    "    %   likelihood error function with regularization) given the parameters \n",
    "    %   of Neural Networks, thetraining data, their corresponding training \n",
    "    %   labels and lambda - regularization hyper-parameter.\n",
    "\n",
    "    % Input:\n",
    "    % params: vector of weights of 2 matrices w1 (weights of connections from\n",
    "    %     input layer to hidden layer) and w2 (weights of connections from\n",
    "    %     hidden layer to output layer) where all of the weights are contained\n",
    "    %     in a single vector.\n",
    "    % n_input: number of node in input layer (not include the bias node)\n",
    "    % n_hidden: number of node in hidden layer (not include the bias node)\n",
    "    % n_class: number of node in output layer (number of classes in\n",
    "    %     classification problem\n",
    "    % training_data: matrix of training data. Each row of this matrix\n",
    "    %     represents the feature vector of a particular image\n",
    "    % training_label: the vector of truth label of training images. Each entry\n",
    "    %     in the vector represents the truth label of its corresponding image.\n",
    "    % lambda: regularization hyper-parameter. This value is used for fixing the\n",
    "    %     overfitting problem.\n",
    "       \n",
    "    % Output: \n",
    "    % obj_val: a scalar value representing value of error function\n",
    "    % obj_grad: a SINGLE vector of gradient value of error function\n",
    "    % NOTE: how to compute obj_grad\n",
    "    % Use backpropagation algorithm to compute the gradient of error function\n",
    "    % for each weights in weight matrices.\n",
    "\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    % reshape 'params' vector into 2 matrices of weight w1 and w2\n",
    "    % w1: matrix of weights of connections from input layer to hidden layers.\n",
    "    %     w1(i, j) represents the weight of connection from unit j in input \n",
    "    %     layer to unit i in hidden layer.\n",
    "    % w2: matrix of weights of connections from hidden layer to output layers.\n",
    "    %     w2(i, j) represents the weight of connection from unit j in hidden \n",
    "    %     layer to unit i in output layer.\"\"\"\n",
    "\n",
    "    n_input, n_hidden, n_class, training_data, training_label, lambdaval = args\n",
    "\n",
    "    w1 = params[0:n_hidden * (n_input + 1)].reshape((n_hidden, (n_input + 1)))\n",
    "    w2 = params[(n_hidden * (n_input + 1)):].reshape((n_class, (n_hidden + 1)))\n",
    "    obj_val = 0\n",
    "\n",
    "    # Your code here\n",
    "    \n",
    "    n = training_data.shape[0]\n",
    "    # Feed forward code\n",
    "    w1_transpose = np.transpose(w1)\n",
    "    w2_transpose = np.transpose(w2)\n",
    "\n",
    "    input_bias = np.ones(shape=(n, 1), dtype = np.float64) # create input bias \n",
    "    biased_training_data = np.append(training_data, input_bias, axis=1) # Add input bias to training data\n",
    "    \n",
    "    aj = np.dot(biased_training_data, w1_transpose) # Product of W and input data\n",
    "    zj = sigmoid(aj) # Sigmoid of dot product\n",
    "    \n",
    "    hidden_bias = np.ones(shape=(zj.shape[0], 1), dtype = np.float64) \n",
    "    biased_zj = np.append(zj, hidden_bias, axis=1)\n",
    "    \n",
    "    bl = np.dot(biased_zj, w2_transpose)\n",
    "    ol = sigmoid(bl)\n",
    "    \n",
    "    # Labelling output\n",
    "    yl = np.zeros(shape=(n, 2), dtype = np.float64) # setting all output values to 0 initially\n",
    "        \n",
    "    for i in range(yl.shape[0]):   \n",
    "        for j in range(yl.shape[1]):\n",
    "            if j==training_label[i]:\n",
    "                yl[i][j] = 1.0             #set the class labeled value to 1 and rest to 0    \n",
    "        \n",
    "    # Error function\n",
    "    \n",
    "    p = yl*np.log(ol) # Element wise multiplication\n",
    "    q = (1-yl)*np.log(1-ol)\n",
    "    sum1 = np.sum(p+q)\n",
    "    constant = -1*n\n",
    "    error = sum1/constant # -(yl*log(ol)+(1-y1)*log(1-ol))/n\n",
    "    \n",
    "    # Regularised error function  \n",
    "    \n",
    "    w1_square_sum = np.sum(np.square(w1))\n",
    "    w2_square_sum = np.sum(np.square(w2))\n",
    "    sum2 = w1_square_sum + w1_square_sum                \n",
    "    reg_factor = (sum2*lambdaval)/(2*n)\n",
    "    reg_error = error + reg_factor\n",
    "    \n",
    "    obj_val = reg_error # Regularised error w.r.t lambda\n",
    "    \n",
    "    \n",
    "    # Make sure you reshape the gradient matrices to a 1D array. for instance if your gradient matrices are grad_w1 and grad_w2\n",
    "    # you would use code similar to the one below to create a flat array\n",
    "    # obj_grad = np.concatenate((grad_w1.flatten(), grad_w2.flatten()),0)\n",
    "    obj_grad = np.array([])\n",
    "\n",
    "    delta_l = ol-yl\n",
    "    delta_l_transpose = np.transpose(delta_l)\n",
    "    \n",
    "    grad_w2 = np.dot(delta_l_transpose, biased_zj)\n",
    "    \n",
    "    r = (1-biased_zj[:,0:n_hidden])*biased_zj[:,0:n_hidden]\n",
    "    s = np.dot(delta_l, w2[:,0:n_hidden])\n",
    "    rs = r*s\n",
    "    rs_transpose = np.transpose(rs)\n",
    "    grad_w1 = np.dot(rs_transpose, biased_training_data)\n",
    "    \n",
    "    # Regularised gradients\n",
    "    \n",
    "    reg_grad_w2 = (grad_w2 + (lambdaval*w2))/n\n",
    "    reg_grad_w1 = (grad_w1 + lambdaval*w1)/n\n",
    "    obj_grad = np.concatenate((reg_grad_w1.flatten(), reg_grad_w2.flatten()),0)\n",
    "    \n",
    "    return (obj_val, obj_grad)\n",
    "    \n",
    "# Replace this with your nnPredict implementation\n",
    "def nnPredict(w1, w2, data):\n",
    "    \"\"\"% nnPredict predicts the label of data given the parameter w1, w2 of Neural\n",
    "    % Network.\n",
    "\n",
    "    % Input:\n",
    "    % w1: matrix of weights of connections from input layer to hidden layers.\n",
    "    %     w1(i, j) represents the weight of connection from unit i in input \n",
    "    %     layer to unit j in hidden layer.\n",
    "    % w2: matrix of weights of connections from hidden layer to output layers.\n",
    "    %     w2(i, j) represents the weight of connection from unit i in input \n",
    "    %     layer to unit j in hidden layer.\n",
    "    % data: matrix of data. Each row of this matrix represents the feature \n",
    "    %       vector of a particular image\n",
    "       \n",
    "    % Output: \n",
    "    % label: a column vector of predicted labels\"\"\"\n",
    "\n",
    "    labels = np.zeros(shape=(data.shape[0], 1))\n",
    "    #labels = np.zeros((data.shape[0],1))\n",
    "    # Your code here\n",
    "\n",
    "    # Feed forward code\n",
    "    input_bias = np.ones(shape=(data.shape[0],1), dtype=np.float64)\n",
    "    biased_data = np.append(data, input_bias, axis=1)\n",
    "    \n",
    "    w1_transpose = np.transpose(w1)\n",
    "    w2_transpose = np.transpose(w2)\n",
    "    \n",
    "    aj = np.dot(biased_data, w1_transpose)\n",
    "    zj = sigmoid(aj)\n",
    "    \n",
    "    hidden_bias = np.ones(shape=(zj.shape[0], 1), dtype=np.float64)\n",
    "    biased_zj = np.append(zj, hidden_bias, axis=1)\n",
    "    \n",
    "    bl= np.dot(biased_zj, w2_transpose)\n",
    "    ol = sigmoid(bl)\n",
    "    \n",
    "    for x in range(ol.shape[0]): # Label prediction\n",
    "        max_arg = np.argmax(ol[x])\n",
    "        labels[x] = max_arg\n",
    "        \n",
    "    return labels\n",
    "\n",
    "# Do not change this\n",
    "def preprocess():\n",
    "    pickle_obj = pickle.load(file=open('face_all.pickle', 'rb'))\n",
    "    features = pickle_obj['Features']\n",
    "    labels = pickle_obj['Labels']\n",
    "    train_x = features[0:21100] / 255\n",
    "    valid_x = features[21100:23765] / 255\n",
    "    test_x = features[23765:] / 255\n",
    "\n",
    "    labels = labels[0]\n",
    "    train_y = labels[0:21100]\n",
    "    valid_y = labels[21100:23765]\n",
    "    test_y = labels[23765:]\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
    "\n",
    "\"\"\"**************Neural Network Script Starts here********************************\"\"\"\n",
    "train_data, train_label, validation_data, validation_label, test_data, test_label = preprocess()\n",
    "#  Train Neural Network\n",
    "# set the number of nodes in input unit (not including bias unit)\n",
    "n_input = train_data.shape[1]\n",
    "\n",
    "# set the number of nodes in output unit\n",
    "n_class = 2\n",
    "\n",
    "n_hidden_array = [4,8,12,16,20]\n",
    "\n",
    "for x in n_hidden_array:\n",
    "    for y in range(0,70,10):\n",
    "        \n",
    "        # set the number of nodes in hidden unit (not including bias unit)\n",
    "        n_hidden = x # values - 4,8,12,16,20\n",
    "\n",
    "        # set the regularization hyper-parameter\n",
    "        lambdaval = y # values - 0 to 60, 10\n",
    "        \n",
    "        # Note current time\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # initialize the weights into some random matrices\n",
    "        initial_w1 = initializeWeights(n_input, n_hidden);\n",
    "        initial_w2 = initializeWeights(n_hidden, n_class);\n",
    "        # unroll 2 weight matrices into single column vector\n",
    "        initialWeights = np.concatenate((initial_w1.flatten(), initial_w2.flatten()),0)\n",
    "        \n",
    "        args = (n_input, n_hidden, n_class, train_data, train_label, lambdaval)\n",
    "\n",
    "        #Train Neural Network using fmin_cg or minimize from scipy,optimize module. Check documentation for a working example\n",
    "        opts = {'maxiter' :50}    # Preferred value.\n",
    "\n",
    "        nn_params = minimize(nnObjFunction, initialWeights, jac=True, args=args,method='CG', options=opts)\n",
    "        params = nn_params.get('x')\n",
    "        #Reshape nnParams from 1D vector into w1 and w2 matrices\n",
    "        w1 = params[0:n_hidden * (n_input + 1)].reshape( (n_hidden, (n_input + 1)))\n",
    "        w2 = params[(n_hidden * (n_input + 1)):].reshape((n_class, (n_hidden + 1)))\n",
    "\n",
    "        print \"\\n lambda:\"+str(lambdaval)\n",
    "        print \"\\n No of Hidden layers:\"+str(n_hidden)\n",
    "        #Test the computed parameters\n",
    "        predicted_label = nnPredict(w1,w2,train_data)\n",
    "        #find the accuracy on Training Dataset\n",
    "        print('\\n Training set Accuracy:' + str(100*np.mean((predicted_label == train_label.reshape(train_label.shape[0], 1)).astype(float))) + '%')\n",
    "        predicted_label = nnPredict(w1,w2,validation_data)\n",
    "        #find the accuracy on Validation Dataset\n",
    "        print('\\n Validation set Accuracy:' + str(100*np.mean((predicted_label == validation_label.reshape(validation_label.shape[0], 1)).astype(float))) + '%')\n",
    "        predicted_label = nnPredict(w1,w2,test_data)\n",
    "        #find the accuracy on Validation Dataset\n",
    "        print('\\n Test set Accuracy:' +  str(100*np.mean((predicted_label == test_label.reshape(test_label.shape[0], 1)).astype(float))) + '%')\n",
    "        \n",
    "        t2 = time.time()\n",
    "        \n",
    "        print '\\n Time taken:'+str(t2-t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
